[
  {
    "objectID": "subscribe.html",
    "href": "subscribe.html",
    "title": "Subscribe",
    "section": "",
    "text": "Subscribe to receive email notifications of new posts."
  },
  {
    "objectID": "posts/06-simulation/index.html",
    "href": "posts/06-simulation/index.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation can be done in a spreadsheet with @Risk (though not on a Mac!) but is better done elsewhere. An easy example of the AI + coding approach is to simulate a retirement plan.\nA simple retirement plan specifies an initial account balance, the number of years and the amount to be saved each year until retirement, the number of years and the amount to be withdrawn each year after retirement, and an investment return each year. We can bypass worrying about inflation by doing everything in real terms: the deposits and withdrawals should be specified in today’s dollars, and the investment return should be the real rate of return. Taxes are complicated and important. It would certainly be feasible to do a detailed analysis of taxes for different investment vehicles (along the lines of this), but, since teaching personal finance is not my real goal, I just tell students to think of the deposits and withdrawals as being pre-tax, as in a 401k.\nOne way to approach the simulation is to ask for a python function to be created that takes an initial account balance, a list of deposit amounts, a list of withdrawal amounts, and a list of investment returns as inputs and produces a table with five columns: the beginning-of-year balance, the % investment return, the dollar investment gain or loss, the deposit or withdrawal amount, and the end-of-year balance. The reason for outputting an entire table rather than just end-of-year balances is that it makes it easier to check that the timing and calculations are done correctly.\nWe don’t have to type the lists that are inputs to the function. We can say, for example: “The initial balance is $40,000, there will be 30 deposits starting at $5,000 and growing by 4% per year, there will be 25 withdrawals of $100,000 each, and the investment return will be 10% each year. Use the function to calculate the table and show it.” We can do a small example to check that the function is working correctly before running the simulation. Julius has a data viewer that makes it easy to examine the results. We can also ask for the results to be output as an Excel file (which produces a file with only numbers, not formulas).\nOnce the function is working correctly, we can ask for a simulation. We can specify the initial balance and deposit and withdrawal lists to be used in the function and then say, for example: “Simulate the investment returns each year as random draws from a normal distribution with a mean of 10% and a standard deviation of 10% and then apply the function. Retain the terminal account balance. Repeat this 1,000 times.” Then, we can ask for the mean or median of the terminal balances, a histogram, etc. The histogram is useful because it shows the positive skewness induced by compounding, which will also show up in the mean being larger than the median. This is a good opportunity to talk about the difference between arithmetic and geometric average returns and the effect of volatility on the difference.\nThis is a nice example to build into an app. Everyone needs to do retirement planning, so students may be able to impress friends and family.\n\nFirst published on finance-with-ai.org"
  },
  {
    "objectID": "posts/04-prompts/index.html",
    "href": "posts/04-prompts/index.html",
    "title": "Prompt Engineering (or Not)",
    "section": "",
    "text": "I use Menti surveys periodically to ask students what they would like to learn more about, and how to write effective prompts frequently shows up. In the first bit of time after ChatGPT 3.5 was introduced, there was a lot of chatter online about prompt engineering This seems to have died down somewhat, and for good reason. The models are so good now that they don’t generally require any special prompting. In particular, you do not need to tell Julius “you are an expert coder …” If any role-setting is even needed now, which is doubtful, I think it must be supplied in the context provided by Julius to the LLMs.\nI take advice on this topic from Ethan Mollick, a Wharton management professor who studies these things and whose blog, One Useful Thing, you should certainly follow, if you do not already. I direct students to one of Mollick’s posts in particular, which discusses good enough prompting. Mollick suggests that instead of worrying about how to write prompts, people should treat an LLM as an “infinitely patient coworker.” I find that I naturally come back to this several times in my course, reminding students “Remember what Ethan Mollick said: treat AI as an infinitely patient coworker.” Actually, I modify the quote from “coworker” to “colleague.” The term “coworker” suggests a peer to me, but AI can serve equally well as a senior colleague who mentors, or a junior colleague who assists, or a peer who collaborates. And, it can move seamlessly from one to the other.\nA question students ask is whether they should give specific instructions in a chat, or just a brief statement of what they want and then see what they get. Here, I say “think of AI as an ininitely patient assistant.” How detailed should the instructions be that you give an assistant? You can be very detailed, but that is a waste of time if the assistant is competent to do the task alone. On the other hand, if you are not detailed, you may find the assistant does something different from what you want, and you have to send him/her/it back to do it again. This process could go on for quite awhile and end up being a waste of time. How to know which path to follow? You need to know your assistant. So, I encourage students to experiment to learn the AI’s capabilities. Some tasks will have appeared frequently in its training data, and it will need very little instruction. It may be less familiar with others and need more. Here, I stress the “infinitely patient” part. You can experiment all you want.\nIf you find yourself on an iterative path of correcting errors, it can often be useful to just start a new chat and this time give detailed instructions. The frustrating part about correcting errors is that the LLM will regenerate code each time and sometimes, when it tries to fix one error, it introduces new errors (I mean doing something other than what you want, not syntax errors that it will fix on its own) in code that worked fine before. If this begins to happen, it is probably time for a fresh start.\nWhat about tasks that involve multiple steps? Should you ask for everything you want in a single prompt or just ask for one step at a time? Again, I ask students to experiment. What they consistently report back to me is that it is better to just ask for one step at a time. However, one thing to keep in mind is that an LLM can be somewhat forgetful. Even though the context windows are large enough today that an LLM will be able to re-read your entire chat each time you prompt it, it cannot be equally attentive to everything in the chat. So, it can be helpful to prompt it in later steps to “use this that you got before and that that you got before and …” instead of relying on it knowing what it should use from previous steps. In order to ensure that the LLM correctly recovers what it created in previous steps, I find it very helpful to structure each step as: “create a python function that … and save it as a .py file”” Then in subsequent steps, I can say “read the .py file and use the python function to …” Then, each successive step can be taken without prior code being rewritten.\nWhat do you think? What works for you? Let us know in the comments below.\n\nFirst published on finance-with-ai.org"
  },
  {
    "objectID": "posts/02-online-data/index.html",
    "href": "posts/02-online-data/index.html",
    "title": "Online Data and Visualization",
    "section": "",
    "text": "Grabbing and visualizing online data is a good place to start to demonstrate to students the power and simplicity of AI + python. Yahoo Finance is a great source of free online data about stock and option prices and corporate financial statements. The yfinance library is the best python library for retrieving it. FRED (Federal Reserve Economic Data) is a great source for macroeconomic data, including GDP, exchange rates, Treasury and corporate bond yields, crude oil prices, etc. The pandas-datareader library is the best python library for accessing FRED. Neither yfinance nor pandas-datareader requires you to obtain an API key.\nComputing stock returns with yfinance is a good starting point. Yahoo Finance computes dividend and split adjusted closing prices. We can compute total close-to-close returns, including dividend returns, as percent changes of the adjusted closing prices.1 The yfinance library recently changed to returning the adjusted prices by default rather than returning standard (split-adjusted) prices. The confusing part is that it now calls the adjusted prices returned by default “Close” rather than the former “Adj Close.” I recommend prompting the LLM to use the latest version of yfinance and explicitly prompting the LLM to get the “Close” instead of “Adj Close.”\nA more complex but also more transparent solution to the Close/Adj Close confusion is to prompt the LLM to use the yfinance download function with auto_adjust set to False (this was the old behavior) and to get both the “Close” and “Adj Close.” Percent changes in “Adj Close” are what you want for returns. To show students the difference between the two, you could ask for percent changes in both and then filter to dates where the percent changes differ by more than 0.00001 or so. Those dates will be the ex-dividend days. The difference between the two percent changes on those days is the quarterly dividend yield.\nThe Yahoo Finance data starts in 1970. To get the longest possible history for a ticker, you can ask it to start in 1970. You can specify other dates and you can specify the frequency of the data - daily, weekly, monthly, quarterly, annual. After computing returns, students can go immediately to creating charts. Python has very versatile plotting libraries. The LLM will default to matplotlib or seaborn, depending on what type of chart you ask for. You can ask Julius to adjust the figure size, font sizes, tick locations, tick labels, axis labels, title, legend positioning, and more. Figures can be saved and downloaded as jpegs, pngs, pdfs, or other types. Different themes can also be applied – gridded or not gridded, light or dark background, etc. Rather than attempting to teach all of these possibilities, I recommend encouraging students to ask Julius what is possible. They should get in the habit of turning to AI for advice, collaboration, and assistance in whatever task they are doing.\nAfter exploring stock returns with yfinance, I turn to exploring FRED data using pandas-datareader. Students can start by going to the FRED website and using point-and-click to find data and download it as csv files. Then, they can turn to Julius to do the same thing more quickly. For example, “get me the history of 10-year Treasury yields from FRED using pandas-datareader at a daily frequency and plot them.” There are alternate ways of getting the FRED data: there are other FRED-specific python libraries and there is the generic requests library. But pandas-datareader provides the easiest access. In subsequent posts, we’ll explore Ken French’s data library, the SEC EDGAR site, and scraping data from websites using the requests and beautiful soup libraries.\nFirst published on finance-with-ai.org"
  },
  {
    "objectID": "posts/02-online-data/index.html#footnotes",
    "href": "posts/02-online-data/index.html#footnotes",
    "title": "Online Data and Visualization",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere is a slight caveat that the percent change of the adjusted closing price on an ex-dividend day takes the dividend out of the denominator of the price ratio rather than adding it to the numerator, but, given typical quarterly dividend yields, this has a negligible effect. Percent changes of adjusted closing prices on all days other than ex-dividend days equal percent changes in split-adjusted closing prices.↩︎"
  },
  {
    "objectID": "posts/00-welcome/index.html",
    "href": "posts/00-welcome/index.html",
    "title": "Teaching Finance with AI",
    "section": "",
    "text": "The purpose of this blog and the site finance-with-ai.org is to communicate things I’ve learned about teaching MBA students at Rice University how to do financial analyses using “AI + coding” and more broadly how generative AI can and is being used in the finance industry. I will post short notes on what I’ve learned about teaching this topic and on related things I find interesting. The blog is intended to be a resource for finance instructors at the undergraduate, MBA, and MSF levels.\nThe current effectiveness of AI + coding varies somewhat between corporate finance and investments applications. Here, I lump fundamental security analysis with corporate finance. There are many topics in the investments area for which spreadsheets were never well equipped and for which spreadsheets are seldom used in practice. Previously, it was difficult to teach those topics by example, but now students can prompt an LLM to generate code for them.\nEven in capital budgeting, financial statement analysis, and pro forma financial valuation, AI is already very valuable. It is not yet ready to replace spreadsheets, but it can be a useful complement to spreadsheets. AI can be used as a collaborator – “tell me how you would do this” or “you do it your way, and I’ll do it my way, and then we can compare answers.” As the models improve, I expect the world to shift more and more to AI in lieu of spreadsheets even for corporate finance applications. Of course, Hewlett-Packard is still making the 12C financial calculator, and Microsoft will undoubtedly sell Excel for many years to come, but I think AI + coding will eventually dominate. To prepare our students for that world, we should start teaching them now about what is likely to lie ahead.\nWhat do you think? Let us know in the comments below.\n\nFirst published on finance-with-ai.org"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Teaching Finance with AI",
    "section": "",
    "text": "The link above is to the materials for the six-week MBA course I taught in Spring 2025. The course is certainly not perfect. It was developed “just in time” and substantially redesigned on the fly. Nevertheless, it seemed to work reasonably well, so I offer it as a possible starting point for people who may want to teach this topic but have not yet done so. If you have experience teaching it or have other things to add, please let us know in the comments below.\nWe all face a difficult job keeping up in this rapidly evolving environment. I hope this site can make that somewhat easier. I would be happy to host guest bloggers or to link content from others to make this a shared resource. Post a comment below to share your views."
  },
  {
    "objectID": "about.html#about-this-site",
    "href": "about.html#about-this-site",
    "title": "Teaching Finance with AI",
    "section": "",
    "text": "The link above is to the materials for the six-week MBA course I taught in Spring 2025. The course is certainly not perfect. It was developed “just in time” and substantially redesigned on the fly. Nevertheless, it seemed to work reasonably well, so I offer it as a possible starting point for people who may want to teach this topic but have not yet done so. If you have experience teaching it or have other things to add, please let us know in the comments below.\nWe all face a difficult job keeping up in this rapidly evolving environment. I hope this site can make that somewhat easier. I would be happy to host guest bloggers or to link content from others to make this a shared resource. Post a comment below to share your views."
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "Teaching Finance with AI",
    "section": "About Me",
    "text": "About Me\nI am Kerry Back, J. Howard Creekmore Professor of Finance and Professor of Economics at Rice University."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Teaching Finance with AI",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nTeaching Finance with AI\n\n\n\n\n\n\n\n\nMay 3, 2025\n\n\nKerry Back\n\n\n\n\n\n\n\n\n\n\n\n\nJulius and the Democratization of Coding\n\n\n\nAI Overview\n\n\n\n\n\n\n\n\n\nMay 4, 2025\n\n\nKerry Back\n\n\n\n\n\n\n\n\n\n\n\n\nOnline Data and Visualization\n\n\n\nFinance\n\nPython Tools\n\n\n\n\n\n\n\n\n\nMay 5, 2025\n\n\nKerry Back\n\n\n\n\n\n\n\n\n\n\n\n\nCAPM and PowerPoint\n\n\n\nFinance\n\nPython Tools\n\n\n\n\n\n\n\n\n\nMay 6, 2025\n\n\nKerry Back\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Engineering (or Not)\n\n\n\nAI Overview\n\n\n\n\n\n\n\n\n\nMay 7, 2025\n\n\nKerry Back\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Apps\n\n\n\nPython Tools\n\n\n\n\n\n\n\n\n\nMay 8, 2025\n\n\nKerry Back\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation\n\n\n\nFinance\n\n\n\n\n\n\n\n\n\nMay 9, 2025\n\n\nKerry Back\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01-julius/index.html",
    "href": "posts/01-julius/index.html",
    "title": "Julius and the Democratization of Coding",
    "section": "",
    "text": "The world is aware that generative AI has made coders more efficient, but I don’t know if there is as much recognition of the more important fact that gen AI has made coding accessible to non-coders. I expect this to change rapidly by word of mouth: Once exposed to the wonder of coding with gen AI, one cannot help but want to share the word. We can accelerate that change for our students.\nThere are many IDEs (integrated development environements) that incorporate AI assistance, among which Cursor may be the most popular at the moment. Those tools are fantastic, but the variety of options makes them intimidating to non-coders. The leading chatbots also have “code interpreters” that execute generated code to respond to prompts. But, as of this writing, those interpreters are closed systems. They provide a fixed menu of libraries and do not allow the user to install more. Julius.ai bridges the gap. It is a full-fledged coding environment, allowing the user to install any library he or she wishes. At the same time, it has the ease of use of a chatbot (and get the 50% academic discount by emailing team@julius.ai from your university email).\nThe Julius website states that it provides an “intuitive way to analyze and visualize data without having to code, making statistical analysis accessible to everyone.” Democratizing coding is the goal of the Julius developers. However, the focus on statistical analysis understates what Julius has to offer. You can choose to work in either python or R. If you choose python, which I recommend, then you can do anything with Julius that python can do, and python can do pretty much everything. We’ll explore lots of applications in subsequent posts. I’ll refer to Julius throughout my posts, because that is what I use in my course, but the things we discuss will generally apply to other AI + python setups as well.\nJulius is a wrapper around large language models (LLMs), including the latest models from OpenAI and Anthropic as of this writing. Julius sends the user’s prompts to the user’s selected LLM (the general consensus in the blogosphere, and my own impression, is that the Anthropic models Claude 3.5 and Claude 3.7 are the best coders available at this time) with additional context created by the Julius developers. If the LLM generates code, then Julius’s servers execute it. The user can see the code as it is written and see what the code creates. The chat is very informative, telling the user what the plan is before the code is generated and then interpreting and explaining the results afterwards. A benefit of this process is that students learn something about coding in a relatively painless way.\nA valid concern about gen AI coding for non-coders is that an LLM may make a mistake that the user cannot detect. When OpenAI released GPT 3.5 in 2022, it frequently hallucinated. It is natural to worry about hallucinations in AI-generated code. One saving grace is that the models have improved tremendously since 2022, and hallucinations are much less common. An equally important consideration is the nature of coding. Hallucinations about facts in coding would be hallucinations about syntax, and incorrect syntax won’t run. Syntax errors certainly happen, but Julius sends the error messages back to the LLM in an iterative manner until, almost always, the syntax is corrected and the code runs. The type of error that usually happens with gen AI coding for non-coders results from the LLM not fully understanding what the user wants. To guard against this, it is important to engage in a two-way conversation with the LLM about what you want, what it understands regarding what you want, what it plans to do, and what it did. Finally, one should try to check code generated by an LLM by testing it on small examples.\nIt is obviously easier to ensure that the LLM did what you want if you can read python code. So, how much python to teach students? Luckily, python is pretty easy to read if you understand the basic structure. I take some time in early sessions of my course to point out: “this is an object, a method of the object is being applied here, this is a function, this is a list …” I also recorded some introductory videos, which are linked in the “Course Materials” (though I doubt they were watched). As I said, a valuable side effect of the course is that students learn something about python, which they feel they need to do, but which they don’t really have the time to do if they had to learn it in a pre-AI mode.\nThere are products that compete with Julius in one way or another that are certainly worth showing to students, and new products are appearing at a rapid pace. Plus, the leading LLM providers are expanding their services. An example of a competing product is Vizly. It has the same data analysis/visualization focus as Julius. The developers were previously at Plotly, and the default plotting library is plotly, which creates very nice interactive HTML plots (you can also use plotly with Julius). Vizly is worth exploring, but I don’t have a lot of experience with it. Casting the net wider, students should be introduced to Google Colab. It is not a chatbot, but it is a free JupyterLab environment with free AI assistance provided by the latest Google model (Gemini 2.5 as of this writing). You start by opening a new notebook or exploring the provided Introduction to Colab notebook. I recommend starting a notebook by asking the AI to mount your Google Drive. Then you can read and write files from your Google Drive (ask the AI to do that also). You can also save your Jupyter notebook there. Casting the net even wider, I highly recommend Replit. It creates very professional web apps, writing the HTML and CSS to create the user interface along with (usually) python to do the actual work. It also provides a hosting service, so you can deploy your app online with just a few clicks. We’ll explore creating apps with Julius in subsequent posts using the python streamlit and gradio libraries.\nThere are many more AI + coding tools out there. Please share your favorites, and share your experiences in teaching finance with AI, in the comments below.\n\nFirst published on finance-with-ai.org"
  },
  {
    "objectID": "posts/03-capm/index.html",
    "href": "posts/03-capm/index.html",
    "title": "CAPM and PowerPoint",
    "section": "",
    "text": "Calculating betas is another easy exercise to do with Julius. We can also estimate the market risk premium, and we can get the risk-free rate from FRED, so we can estimate the cost of equity capital according to the CAPM. This exercise provides the opportunity to explore Ken French’s data library while getting market excess returns and risk-free rates.\nA big advantage of using AI is that things can be automated. A student this spring told me that a friend of his in the finance industry had just used AI to reduce the time required for a certain task he often had to do from two days to two hours. There are many stories like that. To illustrate automation in a simple setting, I use the CAPM calculation to show how PowerPoint decks can be created with AI + python. In a future post, I will explain how to use AI + python to build a web app that estimates a beta, calculates the cost of equity, and generates a PowerPoint deck - the user only has to input a ticker. And, the builder of the app only has to chat with Julius.\nTo estimate betas, we need stock excess returns and market excess returns. I follow the usual academic convention of monthly returns over a 5-year period. To get monthly stock returns we can use yfinance (see Online Data and Visualization). To get adjusted closing prices at a monthly frequency, simply ask Julius for them (the LLM will either use period=“1mo” in yf.download or it will use the pandas resample method to downsample daily prices to monthly prices). Ask for a bit more than five years, because we may lose some months when merging with the market data. Then compute returns as percent changes.\nTo get market excess returns and the risk-free rate, we can use French’s data library. It’s interesting to start by asking Julius to list the datasets available in French’s data library. Then ask Julius to get the monthly three factors using pandas-datareader starting in 1926 and to compute the mean of Mkt-RF for the market risk premium estimate. You’ll want to annualize the market risk premium estimate (or you could just ask for the annual factors and the mean of annual Mkt-RF). If you don’t explicitly ask for pandas-datareader to be used, the LLM may write code to directly read the csv files on French’s website into pandas dataframes, which doesn’t work well, because each file contains text and contains multiple tables (monthly, annual, etc.).\nTo estimate betas, we want to first do an inner merge of the Fama-French data with the stock return data. There are two issues. First, the stock return data will be in decimals and the Fama-French data is in percents. The LLM will probably notice that, but it is good to explicitly ask to convert the stock returns to percents or the Fama-French data to decimals (your choice). The second issue is that the dates will be in different formats. Pandas-datareader will return the Fama-French dates in what is called the pandas period format, whereas the stock return format will be in the pandas timestamp format. Julius will figure this out also, but it may speed up the merge to warn it that the date formats will need to be reconciled. Once the data is merged, keep the last 60 months for which there are no missing data, calculate excess stock returns by subtracting RF (which is in the Fama-French three factor dataset), and then ask Julius to run the regression.\nOnce the beta is estimated, the final step is to get the current risk-free rate. I ask Julius to get the latest value of the three-month T-bill yield from FRED, but it can get different rates if you prefer something else. At this point, you can just ask Julius to compute the cost of equity. The LLMs know the CAPM formula.\nPowerPoint decks can be created in python with the python-pptx library. The details are not important, because the LLMs know them. I like to ask Julius to create a PowerPoint deck with two slides, the first being a scatterplot representing the regression, and the second being a table showing the cost of equity calculation. Usually, it delivers a nice looking deck without any further prompting, but you may want to fine tune it in an iterative way. It will prbably use the seaborn regplot function to produce the scatterplot with the regression line. Sometimes it will show a confidence interval band around the regression line representing the standard errors in the coefficient estimates. When this happens, I ask Julius to remove it, but you may have a different preference.\nIf you try this, let us know how it goes in the comments below.\n\nFirst published on finance-with-ai.org"
  },
  {
    "objectID": "posts/05-apps/index.html",
    "href": "posts/05-apps/index.html",
    "title": "Creating Apps",
    "section": "",
    "text": "After the last session of my class in the spring, a student came up to me and said “I want to thank you. I never knew anything about programming, and now I can create apps. It’s amazing!” We have a few years, I think, when we can be the first to show students the power of AI + coding and have these rewarding moments. But soon everyone will know, and I’m not sure what we’ll do then. Maybe AI will teach our courses.\nA significant upside to app creation is that it makes the code permanent. Using AI + python to do a task repeatedly runs into the issue that there is some randomness in LLM code generation. The code will not be exactly the same each time. Given that it is important to verify that the code is correct (for example, by running it on small examples), this poses a problem. Putting working code in an app avoids this problem. It also makes the process of using the code simpler - there is no need to write a prompt each time.\nThe streamlit, gradio, and dash libraries allow us to create web apps using only python code. The libraries provide python wrappers around HTML, CSS, and JavaScript. AI allows us to create web apps using those libraries just by prompting, because LLMs know the streamlit, gradio, and dash syntax. There are other tools (like Replit) that directly take user prompts and write HTML, CSS, and JavaScript as well as python. I show students Replit but stick primarily with Julius and streamlit or gradio.\nI got some experience in creating apps when my colleague Kevin Crotty and I built an interactive app to illustrate financial concepts: Learn Investments @ Rice Business. It wasn’t long after finishing it that I realized that pretty much everything we had painstakingly constructed (with the great help of the dash and plotly libraries) could be generated by AI + coding with very little effort. Oh, well. At least I still have my day job.\nTo illustrate app creation for students, I return to the cost of equity calculation and ask Julius to create a streamlit (or gradio, which is very similar) app that allows the user to input a ticker, computes the cost of equity as before, and creates and downloads the PowerPoint deck as before.\nCreating this app is a multi-step process. As discussed in a previous post, a safe way to do this is to ask for a python function to be created at each step and saved as a .py file. For example, (i) a function that takes a user-supplied ticker, estimates the beta and returns the beta and a regression plot, (ii) a function that takes a beta and returns a dictionary with the risk-free rate, beta, market risk premium, and cost of equity as the keys and the calculated values as the values, and (iii) a function that takes the regression plot and dictionary as inputs and returns a PowerPoint deck. As step (iv), we can ask Julius to put these together to create an app that allows the user to input a ticker and downloads the PowerPoint deck.\nUnfortunately, as of this writing, Julius cannot directly run the streamlit app. It is necessary to ask for an app.py file, download the app.py file, and run it on your own computer. To do this, you need python installed on your computer. I’m hopeful that the Julius developers will soon make this simpler. In the meantime, you can ask Julius how to install python, and you can ask Julius how to run the app on your own computer. I spend time in class walking students through the process (I also recorded some videos explaining the process, but I’m doubtful anyone ever looked at them!).\nOnce the app is running on your computer, there is an option to deploy it in the cloud. The easiest options are the free Streamlit Community Cloud for streamlit and the free Hugging Face Spaces for gradio. However, this also takes a couple of steps (for example, creating a github repo), so I’ve done the deployment for students myself when they want it. Several students wanted to deploy their course projects to show to prospective employers. Free deployment on either Streamlit or Hugging Face has the downside that the app is “put to sleep” after a couple of days of inactivity and has to be manually restarted. For permanent deployment, I deploy to Koyeb though there are other similar services. Here is the cost of equity app on Koyeb, the github repo it was deployed from, and the Julius thread that created it.\nCloud deployment is often unnecessary. If someone creates an app to automate a task, they do not need to deploy it in the cloud. They can simply run it on their own computer each time they need to perform the task.\nCreating apps is not the first thing I would do in a course, because running an app either locally or in the cloud does take a few extra steps. But, when students begin to get bored because everything is too easy when AI does all of the work, then creating apps is a good way to rekindle interest. Post in the comments below to let us know how it goes if you try it or to let us know if this post omits some good app-creation options.\n\nFirst published on finance-with-ai.org"
  }
]