<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Teaching Finance with AI</title>
<link>https://finance-with-ai.org/</link>
<atom:link href="https://finance-with-ai.org/index.xml" rel="self" type="application/rss+xml"/>
<description>Teaching the use of generative AI in finance</description>
<generator>quarto-1.7.31</generator>
<lastBuildDate>Wed, 14 May 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>SEC EDGAR</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/13-edgar/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/13-edgar/edgar.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>We can get financial statements from Yahoo Finance, but students understandably expect to get data from more professional sources. There is no source for financial statement data that is more authoritative than <a href="https://www.sec.gov/search-filings">SEC EDGAR</a>, the site to which companies upload their SEC filings. There are a number of python libraries designed to help with getting data from EDGAR, but I do not recommend them, in part because the different libraries with different syntaxes cause confusion for LLMs.</p>
<p>A point-and-click method to find a 10-K or 10-Q is to enter a ticker at the EDGAR home page linked in the previous paragraph. That brings up a pop-up window showing the company’s CIK (Central Index Key) and the company’s name. Clicking on the company’s name brings us to a home page for SEC filings for that company. Following the links there, we can find 10-K’s or 10-Q’s that we can read in our browser. I’ll discuss web scraping in a future post, but, for now, I will only say that those pages are not easy for machines to read, because they are dynamically generated.</p>
<p>Fortunately, there is an alternative. Reading the <a href="https://www.sec.gov/search-filings/edgar-application-programming-interfaces">EDGAR API docs</a>, we see that we can download data by going to a specific URL in a web browser. To get all financial statement data for a company, we go to https://data.sec.gov/api/xbrl/companyfacts/CIKxxxxxxxxxx.json. Here, xxxxxxxxxx should be replaced by the company’s 10-digit (zero padded) CIK, which, as already discussed, we can obtain from the EDGAR page linked above. For example, we can get Tesla’s data from <a href="https://data.sec.gov/api/xbrl/companyfacts/CIK0001318605.json">https://data.sec.gov/api/xbrl/companyfacts/CIK0001318605.json</a>.<br>
This json file is not easy to read when opened in a browser, but it is easy for a machine to read. All we need to do is to ask Julius to go to https://data.sec.gov/api/xbrl/companyfacts/CIKxxxxxxxxxx.json and to read the json file into a pandas dataframe. We probably want to also ask it to separate the annual data from the quarterly data.</p>
<p>While playing with this, I decided to create a Streamlit app (as discussed <a href="https://finance-with-ai.org/posts/07-apps/">here</a>) that encapsulates the process. With Julius’ help, I created <a href="https://edgar.finance-with-ai.org">edgar.finance-with-ai.org</a> that follows the steps described above to get the json file for a user-supplied ticker. It reads the json file into a pandas dataframe, separates the 10-Q’s from the 10-K’s and provides download links for Excel files containing the data. That makes it easy for students to work with the data outside of Julius and python.</p>
<p>This EDGAR-supplied data does not come nicely formatted. Instead, we get all of the data items that were uploaded to the SEC. In the examples I’ve looked at, there are over 400 10-K items and over 200 10-Q items. These do include the main statement components: revenue, cost of revenue, current assets, etc. It is a good exercise for finance students to try to build “pretty” statements from these data items.</p>
<p>There is a lot of data on the SEC EDGAR site other than financial statement data. For example, we can get Form 4’s and Schedule 13-F’s there. I’ll discuss extracting other data in a future post.</p>
<hr>
<p><em>First published on <a href="https://finance-with-ai.org">finance-with-ai.org</a></em> <br> <em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Finance</category>
  <guid>https://finance-with-ai.org/posts/13-edgar/</guid>
  <pubDate>Wed, 14 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/13-edgar/edgar.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Fama-French Factors</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/12-fama-french/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/12-fama-french/factors.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>The CAPM is intuitively reasonable and is <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3994848">widely used by companies to estimate their cost of capital</a>, but it is well known to do a poor job of explaining average returns. I like to show students this <a href="https://learn-investments.rice-business.org/capm/sml-industries">interactive plot</a> of estimated betas and average returns for the Fama-French 48 industries. Hovering over the data points brings up the industry names. As students should expect, we see tobacco, alcoholic beverages, and defense among the low beta industries, and we see steel and construction among the high beta industries. However, we see very little difference between the average returns of low beta industries and high beta industries. In other words, the empirical security market line is too flat, as is well known. Other pages on the same website show the <a href="https://learn-investments.rice-business.org/factor-investing/quintiles">returns</a> of characteristic-sorted portfolios and their <a href="https://learn-investments.rice-business.org/capm/two-way-capm">CAPM alphas and t-statistics</a>, drawing on <a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">Ken French’s data library</a>.</p>
<p>The Fama-French model is <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3994848">seldom used by companies to estimate their cost of capital</a>, but it and other factor models are often used as attribution analysis when evaluating the performance of fund managers. To conduct such an analysis, we can follow the same process as for the <a href="https://finance-with-ai.org/posts/04-capm/">CAPM regression</a> and <a href="https://finance-with-ai.org/posts/11-alpha/">Jensen’s alpha</a> but asking Julius to get the five Fama-French factors from French’s data library and to regress excess returns on the five factors. We can calculate the contribution of each factor to the average fund (or stock) return by multiplying the factor beta by the mean factor value over the sample.</p>
<p>This exercise could obviously be done in a spreadsheet, but it is a different experience doing it with AI + python. With AI + python, students can get all the data themselves quickly, and it is also quick to run the regression and compute factor contributions. Because we don’t have to spend time explaining how to implement the calculations, there is more time to discuss why it could be reasonable to regard the Fama-French factors as proxies for risks that investors care about and which are consequently priced - or to discuss any other view one might have about the Fama-French model. Plus, the LLMs know about the Fama-French model, and, at least with Julius, their chatting will reinforce students’ learning.</p>
<hr>
<p><em>First published on <a href="https://finance-with-ai.org">finance-with-ai.org</a></em></p>



 ]]></description>
  <category>Finance</category>
  <guid>https://finance-with-ai.org/posts/12-fama-french/</guid>
  <pubDate>Tue, 13 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/12-fama-french/factors.png" medium="image" type="image/png" height="100" width="144"/>
</item>
<item>
  <title>Jensen’s Alpha</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/11-alpha/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/11-alpha/alpha.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>“Alpha” in this post will mean the CAPM alpha, that is, the intercept in the CAPM regression. It was first used to measure mutual fund performance by Michael Jensen, and, when used in that context, it is called Jensen’s alpha. It is worth stressing to students that a positive alpha does not mean that an investor should move all of his or her money into the fund. A fund can have a positive alpha but have a lower Sharpe ratio than the market. In fact, a fund has a positive alpha if and only if its Sharpe ratio is larger than the market’s Sharpe ratio <em>multiplied by the correlation between the fund and the market</em>. Because correlations are less than one, the Sharpe ratio hurdle for a fund to earn positive alpha is lower than the market Sharpe ratio. An interactive figure illustrating this principle can be found <a href="https://learn-investments.rice-business.org/capm/alphas-sharpes">here</a>. An extreme example is a fund with a zero beta. Such a fund has a positive alpha if and only if its Sharpe ratio is positive, meaning that it beats the risk-free return on average.</p>
<p>While investors should not necessarily move all of their money to a positive alpha fund, they should move some of their money to the fund, assuming they care only about mean and variance and not higher moments. Mean-variance efficiency can be improved by shifting money from the market to a positive alpha fund. This is shown by Dybvig and Ross (Journal of Finance, 1985).</p>
<p>In an <a href="https://finance-with-ai.org/posts/04-capm">earlier post</a>, I explained how to use Julius to run the CAPM regression, using stock prices from Yahoo and using market and risk-free returns from <a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">French’s data library</a>. We can do the same with a mutual fund ticker. Rather than using the most recent 60 months as in the earlier post, I prefer to run the regression for this exercise using all available data. Then, we can ask Julius to compute the beta-hedged mutual fund return each month. By beta hedging, I mean taking out the market exposure as R - beta * (Rm - Rf). According to the CAPM, the average value of this beta-hedged return should be the risk-free return Rf. We can ask Julius to compound the risk-free returns and compound the beta-hedged mutual fund returns over time and plot them. If the beta-hedged returns outperform the risk-free returns, then the fund earned alpha. It is useful to ask for a log scale on the y axis in the plot. Then, we can easily see the periods in which the fund did better than it should have given its market exposure (the slope of the hedged fund curve is greater than the slope of the risk-free curve) and the periods in which it did worse.</p>
<p>A good example for this exercise is Fidelity Magellan (ticker=FMAGX). The fund was an extreme outlier in terms of performance under the stewardship of Peter Lynch but underperformed substantially afterwards. Of course, we expect outliers in a random sample.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Finance</category>
  <guid>https://finance-with-ai.org/posts/11-alpha/</guid>
  <pubDate>Mon, 12 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/11-alpha/alpha.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>API Calls</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/10-apis/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/10-apis/apis.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>This <a href="https://hbsp.harvard.edu/product/HEC382-PDF-ENG">HBS case</a>, about implementing generative AI at Deloitte Canada, is a useful tool for teaching the benefits, risks, and strategies of implementing AI in a corporate environment. Efficiency is of course the key benefit, and data security, client trust, and compliance are key concerns. The general strategy for implementation involves creating a custom channel through which all employees chat with an LLM, a channel that passes relevant corporate standards to the LLM in each chat, that allows monitoring, and that includes a guarantee of data privacy. To complement the case, I show students that they can use Julius to create a mini version of this, namely a custom chatbot that adds whatever context they want to each prompt. This can be done with a custom GPT from OpenAI, but seeing code that produces a custom chatbot makes everything more transparent.</p>
<p>To create this, we need an API key from an LLM provider. As of this writing, OpenAI provides keys even on free accounts. Billing is on a per-use basis, and it is miniscule at demonstration scales. As I will explain, there are also API keys for LLMs that are completely free. Julius provides a facility for storing an API key as a “secret key.” It is not exposed to the LLM during the coding that creates the custom chatbot.</p>
<p>To start the exercise, it is useful to show students the code that executes an API call without all the surrounding code that creates an app. I gave Julius the following example prompt:<sup>1</sup> “send the following to openAI GPT-4 using my api key that is stored as a secret key - What is the best type of pizza? Answer in pig Latin.” Here is the code that Claude 3.5 wrote in response:</p>
<pre><code>from openai import OpenAI
import os

# Initialize the OpenAI client with the API key
client = OpenAI(api_key=os.environ.get('OPEN_AI_KEY'))

# Send the query
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "What is the best type of pizza?  Answer in pig Latin."}
    ]
)

# Print the response
print("Response:", response.choices[0].message.content)</code></pre>
<p>We can see from the code that the messages will be sent to OpenAI’s GPT-4 (note that the LLM you’re using in Julius will balk if you ask for an API call to an LLM that appeared after the training of your Julius LLM - for example, you can’t get GPT-o3 using Claude 3.5 - but you can edit the code in Julius to select the model you want). The “messages” object is a list containing a single dictionary (it can have many more, as we will see in a moment). The dictionary has two keys: “role” and “content.” The response object contains the LLM’s response, and the content of the response is accessed as response.choices[0].message.content. When the code is executed, the computer executing it sends the messages, gets the response, and prints the content of the response. All of the work is done by the “client” object, which is created by the OpenAI function, using my API key that the os.environ.get function reads from its “secret key” storage. What I got from Julius after the code executed was “The GPT-4 model responded with: Response: Epperonipay.””</p>
<p>To create a custom chatbot, it is enough to say something like “Create a custom chatbot as a streamlit app. It should send prompts to GPT-4 using my openai api key that is stored as a secret key. The following additional context should be provided: You are a business professional. Answer in a business-like fashion.” Of course, you could also do more interesting things, like requesting an answer in Pig Latin perhaps. The heart of the code that Claude 3.5 wrote for me is</p>
<pre><code>messages = [
        {"role": "system", "content": 
        "You are a business professional.  Answer in a business-like fashion."}
    ]
    
    while True:
        # Get user input
        user_input = input("You: ").strip()
        
        # Check for quit command
        if user_input.lower() == 'quit':
            break
        
    # Add user message to history
    messages.append({"role": "user", "content": user_input})
    

        # Get response from OpenAI
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            stream=True
        )
        
        # Print assistant response
        print("Bot: ", end="", flush=True)
        full_response = ""
        
        # Stream the response
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                full_response += content
        
        print()  # New line after response
        
        # Add assistant response to history
        messages.append({"role": "assistant", "content": full_response})</code></pre>
<p>This initializes the message list with the context I provided about being a business professional. Then it sets up a “while” loop that runs until the app is exited. Within the loop, each new prompt is added to the message list and the now longer list is sent to the LLM. The LLM response is printed each time and added to the message list also. In this way, the LLM receives the entire chat history following each user prompt.</p>
<p>On the first occasion that I requested this Streamlit app from Julius, I received instead a python script (a .py file) that when executed in my terminal created a chatbot running in the terminal. That is interesting too. If/when you do get a Streamlit app and if you want to deploy it to the cloud, take advantage of the cloud provider’s secret key procedure to maintain security of your API key.</p>
<p>We can get free access to a number of open source LLMs via services like <a href="https://huggingface.co/">Hugging Face</a> and <a href="https://openrouter.ai/">Open Router</a>. Open Router describes itself as “The Unified Interface for LLMs.” It provides access to over 300 LLMs as of this writing. It is worth visiting Open Router in class just to show students the number of LLMs that have been created.</p>
<p>The essence of the Open Router service is that we get an API key from the provider(s) we want to use, store the key(s) at Open Router, and also get an API key from Open Router. We direct all our API calls to Open Router, specifying an LLM to use, and Open Router forwards the calls to the LLM. This provides a unified syntax for API calls (Open Router uses the OpenAI standard) and also unified billing (the LLM providers charge Open Router which then charges us). For someone who is not a heavy user of API calls, the prime benefit of using Open Router is that it provides free access to many open source LLMs.</p>
<p>I take this discussion as an opportunity to show students <a href="https://replit.com/~">Replit</a>, which is an AI + coding platform focused on app creation. Before class, as an illustration, I created a <a href="(https://guardian-pulse-kerryback.replit.app/)">chatbot app</a> that scrapes headlines from <a href="https://www.theguardian.com/us">The Guardian</a> and sends them to the free LLama 4 Scout model for a determination as to whether it is a good, bad, or mixed news day and then allows for additional chatting. It is, of course, just a toy, but it is a concrete example of the chatbot creation process. By the way, I was happy I did this before class rather than during class, because Replit experienced a frustrating amount of confusion between OPENAI_API_KEY and OPEN_ROUTER_API_KEY. LLMs are usually very smart but can sometimes be surprisingly dumb.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Pig Latin is a very old English language variation, mostly of interest to children, that moves any initial consonant phoneme of a word to the end and also adds “ay” to the end of each word. I think I should credit this example to some blog post that I read sometime, but which post escapes me.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI Overview</category>
  <guid>https://finance-with-ai.org/posts/10-apis/</guid>
  <pubDate>Sun, 11 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/10-apis/apis.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Mean-Variance Frontier</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/09-mean-variance/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/09-mean-variance/mean-variance.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>Mean-variance optimization is one of those topics that has always been awkward to teach with spreadsheets. It is messy to define the portfolio variance in a spreadsheet for more than two assets, and we are forced to use Solver to find efficient portfolios or to deal with Excel’s matrix algebra functions that operate on arrays. Also, if we create an example for three assets and someone asks about four, then we have to almost entirely reengineer the spreadsheet. I don’t think we actually expect students to do mean-variance analysis in a spreadsheet after they graduate - we’re just teaching the concept (I think). But, we can now teach the concept without the clunkiness of setting it up in a spreadsheet.</p>
<p>We want to generate the classic figure above and to find the portfolios crresponding to the efficient mean-variance combinations. I prefer to start with the tangency portfolio, because it is simpler than finding the frontier of only risky assets, and because it is where we want to end up anyway. We can specify the risk-free rate, the expected returns of the assets, the standard deviations of the assets and their correlations and just ask Julius to compute the tangency portfolio. The LLMs know how to do it. With high probability, they will generate code to compute the familiar Sigma inverse times mu and then divide by the sum of the elements of that vector so the weights sum to one (it is possible but much less likely that they will use a numerical optimization algorithm from scipy to maximize the Sharpe ratio). This means that we have to explain Sigma inverse times mu.</p>
<p>I take a very hand-waving approach to explain the formula. I remind students first that at the top of a hill the slope must be zero and second that the slope of a function is its derivative, so a maximum is the solution of an equation “derivative = 0.” Of course, they have all seen that at some point in their lives. I then show them (without deriving) the equations for maximizing the Sharpe ratio with three risky assets:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/09-mean-variance/equations.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>I explain that this system of equations is written as Sigma times w equals risk premia, explaining matrix multiplication briefly, and then say that it can be solved for w with a matrix version of “dividing by” Sigma. That seems to give enough intuition for the formula w = Sigma inverse times risk premia.</p>
<p>Asking next for the global minimum variance portfolio is a natural thing to do. The LLM is likely to use the calculus/algebra solution for that also. It is of course the same process as calculating the tangency portfolio but with the risk premia replaced by a vector of constants, for example, a vector of 1’s. If we then ask for the portfolio of only risky assets that achieves a target expected return with minimum risk, we are more likely to see the LLM use an optimizer from scipy. Here, too, I have seen Claude use the calculus/algebra solution, but it is a bit more complicated and evidently appeared less often in the training data than did the solution for the tangency portfolio.</p>
<p>We can also impose position limits, including short sales constraints. In fact, the “no short sales” constraint seems to have appeared so often in the training data that the LLM may impose it when it uses an optimizer even if you have not asked for it. It pays to check the code. If students look, they should be able to decipher the code well enough to see if nonnegativity constraints were imposed. It is also pretty reliable to just ask the LLM if it used nonnegativity constraints, or you may want to say explicitly not to impose them if you don’t want them (to get it to obey, you may need to be emphatic: “It is important that you do not impose short sales constraints. Please pay attention to this.”)</p>
<p>Mean-variance optimization is used in practice mainly for strategic asset allocation, so it is good to demonstrate it on asset classes. Yahoo ETF data is an easy source, though the time series is short. <a href="https://pages.stern.nyu.edu/~adamodar/">Aswath Damodoran</a> maintains some data on his website at NYU, in particular <a href="https://pages.stern.nyu.edu/~adamodar/pc/datasets/histretSP.xls">this</a>. If students want to check their results, they could do so with <a href="https://learn-investments.rice-business.org/portfolios/tangency">this page</a> and <a href="https://learn-investments.rice-business.org/portfolios/optimal-N">this</a> from the website I created with Kevin Crotty. I’ve always liked the <a href="https://hbsp.harvard.edu/product/211004-PDF-ENG?Ntt=harvard%20management%20company">Harvard Management Company</a> case from HBS for teaching mean-variance analysis, because it provides some perspective on the unreliability of unconstrained mean-variance optimization (and the fact that imposing position constraints may mean that you just get your constraints back as the solution).</p>
<p>Please share your thoughts in the comments below.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Finance</category>
  <guid>https://finance-with-ai.org/posts/09-mean-variance/</guid>
  <pubDate>Sat, 10 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/09-mean-variance/mean-variance.png" medium="image" type="image/png" height="104" width="144"/>
</item>
<item>
  <title>Simulation</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/08-simulation/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/08-simulation/monte-carlo.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>Simulation can be done in a spreadsheet but is better done elsewhere. An easy example of the AI + coding approach is to simulate a retirement plan.</p>
<p>A simple retirement plan specifies an initial account balance, the number of years and the amount to be saved each year until retirement, the number of years and the amount to be withdrawn each year after retirement, and an investment return each year. We can bypass worrying about inflation by doing everything in real terms: the deposits and withdrawals should be specified in today’s dollars, and the investment return should be the real rate of return. Taxes are complicated and important. It would certainly be feasible to do a detailed analysis of taxes for different investment vehicles (along the lines of <a href="https://learn-investments.rice-business.org/taxes/tax_vehicles">this</a>), but, since teaching personal finance is not my real goal, I just tell students to think of the deposits and withdrawals as being pre-tax, as in a 401k.</p>
<p>One way to approach the simulation is to ask for a python function to be created that takes an initial account balance, a list of deposit amounts, a list of withdrawal amounts, and a list of investment returns as inputs and produces a table with five columns: the beginning-of-year balance, the % investment return, the dollar investment gain or loss, the deposit or withdrawal amount, and the end-of-year balance. The reason for outputting an entire table rather than just end-of-year balances is that it makes it easier to check that the timing and calculations are done correctly.</p>
<p>We don’t have to type the lists that are inputs to the function. We can say, for example: “The initial balance is $40,000, there will be 30 deposits starting at $5,000 and growing by 4% per year, there will be 25 withdrawals of $100,000 each, and the investment return will be 10% each year. Use the function to calculate the table and show it.” We can do a small example to check that the function is working correctly before running the simulation. Julius has a <a href="https://julius.ai/docs/data-explorer/overview">data viewer</a> that makes it easy to examine the results. We can also ask for the results to be output as an Excel file (which produces a file with only numbers, not formulas).</p>
<p>Once the function is working correctly, we can ask for a simulation. We can specify the initial balance and deposit and withdrawal lists to be used in the function and then say, for example: “Simulate the investment returns each year as random draws from a normal distribution with a mean of 10% and a standard deviation of 10% and then apply the function. Retain the terminal account balance. Repeat this 1,000 times.” Then, we can ask for the mean or median of the terminal balances, a histogram, etc. The histogram is useful because it shows the positive skewness induced by compounding, which will also show up in the mean being larger than the median. This is a good opportunity to talk about the difference between arithmetic and geometric average returns and the effect of volatility on the difference.</p>
<p>This is a nice example to build into an app. Everyone needs to do retirement planning, so students may be able to impress friends and family.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Finance</category>
  <guid>https://finance-with-ai.org/posts/08-simulation/</guid>
  <pubDate>Fri, 09 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/08-simulation/monte-carlo.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Creating Apps</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/07-apps/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/07-apps/apps.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>After the last session of my class in the spring, a student came up to me and said “I want to thank you. I never knew anything about programming, and now I can create apps. It’s amazing!” We have a few years, I think, when we can be the first to show students the power of AI + coding and have these rewarding moments. But soon everyone will know, and I’m not sure what we’ll do then. Maybe <a href="https://www.chronicle.com/article/are-you-ready-for-the-ai-university">AI will teach our courses</a>.</p>
<p>A significant upside to app creation is that it makes the code permanent. Using AI + python to do a task repeatedly runs into the issue that there is some randomness in LLM code generation. The code will not be exactly the same each time. Given that it is important to verify that the code is correct (for example, by running it on small examples), this poses a problem. Putting working code in an app avoids this problem. It also makes the process of using the code simpler - there is no need to write a prompt each time.</p>
<p>Another important feature of app creation is that it enables us to ensure data privacy. By creating an app that is run locally, we can avoid ever exposing our data. We can use a small artificial dataset when creating the app, and then we can run the app on the real data on our own computer, even if it is disconnected from the internet.</p>
<p>The streamlit, gradio, and dash libraries allow us to create web apps using only python code. The libraries provide python wrappers around HTML, CSS, and JavaScript. AI allows us to create web apps using those libraries just by prompting, because LLMs know the streamlit, gradio, and dash syntax. There are other tools (like <a href="https://replit.com/">Replit</a>) that directly take user prompts and write HTML, CSS, and JavaScript as well as python. I show students Replit but stick primarily with Julius and streamlit or gradio.</p>
<p>I got some experience in creating apps when my colleague <a href="https://kevin-crotty.com/">Kevin Crotty</a> and I built an interactive app to illustrate financial concepts: <a href="learn-investments.rice-business.org">Learn Investments @ Rice Business</a>. It wasn’t long after finishing it that I realized that pretty much everything we had painstakingly constructed (with the great help of the dash and plotly libraries) could be generated by AI + coding with very little effort. Oh, well. At least I still have my day job.</p>
<p>To illustrate app creation for students, I return to the <a href="https://finance-with-ai.org/posts/04-capm">cost of equity</a> calculation and ask Julius to create a streamlit (or gradio, which is very similar) app that allows the user to input a ticker, computes the cost of equity as before, and creates and downloads the <a href="https://finance-with-ai.org/posts/05-building">PowerPoint deck</a> as before.</p>
<p>Creating this app is a multi-step process. As discussed in a <a href="https://finance-with-ai.org/posts/04-prompts/">previous post</a>, a safe way to do this is to ask for a python function to be created at each step and saved as a .py file. For example, (i) a function that takes a user-supplied ticker, estimates the beta and returns the beta and a regression plot, (ii) a function that takes a beta and returns a dictionary with the risk-free rate, beta, market risk premium, and cost of equity as the keys and the calculated values as the values, and (iii) a function that takes the regression plot and dictionary as inputs and returns a PowerPoint deck. As step (iv), we can ask Julius to put these together to create an app that allows the user to input a ticker and downloads the PowerPoint deck.</p>
<p>Unfortunately, as of this writing, Julius cannot directly run the streamlit app. It is necessary to ask for an app.py file, download the app.py file, and run it on your own computer. To do this, you need python installed on your computer. I’m hopeful that the Julius developers will soon make this simpler. In the meantime, you can ask Julius how to install python, and you can ask Julius how to run the app on your own computer. I spend time in class walking students through the process (I also recorded some videos explaining the process, but I’m doubtful anyone ever looked at them!).</p>
<p>Once the app is running on your computer, there is an option to deploy it in the cloud. The easiest options are the free <a href="https://streamlit.io/cloud">Streamlit Community Cloud</a> for streamlit and the free <a href="https://huggingface.co/spaces">Hugging Face Spaces</a> for gradio. However, this also takes a couple of steps (for example, creating a github repo), so I’ve done the deployment for students myself when they want it. Several students wanted to deploy their course projects to show to prospective employers. Free deployment on either Streamlit or Hugging Face has the downside that the app is “put to sleep” after a couple of days of inactivity and has to be manually restarted. For permanent deployment, I deploy to <a href="https://www.koyeb.com/docs/deploy/streamlit">Koyeb</a> though there are other similar services. Here is the <a href="https://costofequity.koyeb.app/">cost of equity app</a> on Koyeb, the <a href="https://github.com/finance-with-ai/streamlit-cost-equity">github repo</a> it was deployed from, and the <a href="https://julius.ai/s/9ac52a0d-669c-47b0-a4f0-40d370e3ad35">Julius thread</a> that created it.</p>
<p>Cloud deployment is often unnecessary. If someone creates an app to automate a task, they do not need to deploy it in the cloud. They can simply run it on their own computer each time they need to perform the task.</p>
<p>Creating apps is not the first thing I would do in a course, because running an app either locally or in the cloud does take a few extra steps. But, I think it is an important thing to show students at some point. Post in the comments below to let us know how it goes if you try it or to let us know if this post omits some good app-creation options.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Python Tools</category>
  <guid>https://finance-with-ai.org/posts/07-apps/</guid>
  <pubDate>Thu, 08 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/07-apps/apps.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Building Stuff</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/05-building/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/05-building/building.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>A big advantage of coding (and using AI to write code) is that things can be automated. A student this spring told me that a friend of his in the finance industry had just used AI to reduce the time required for a certain task he often had to do from two days to two hours. There are many stories like that. To illustrate automation in a simple setting, we can use the <a href="https://finance-with-ai.org/posts/04-capm">CAPM calculation</a> to show how PowerPoint decks can be created with AI + python.</p>
<p>PowerPoint decks can be created in python with the python-pptx library. The details are not important, because the LLMs know them. I ask Julius to create a PowerPoint deck with two slides, the first being a scatterplot representing the regression, and the second being a table showing the cost of equity calculation. Usually, it delivers a nice looking deck without any further prompting, but you may want to fine tune it in an iterative way. It will probably use the seaborn regplot function to produce the scatterplot with the regression line. Sometimes it will show a confidence interval band around the regression line representing the standard errors in the coefficient estimates. When this happens, I ask Julius to remove it, but you may have a different preference.</p>
<p>We can also create Word docs. It is interesting to ask for the same plot and table and for some discussion of the results to be saved as a Word doc. Python can create Excel files, with multiple worksheets, but it can only produce tables of data. It does not write Excel formulas into a workbook. There are other AI tools for working with Excel files, but they are not the subject of today’s post.</p>
<p>To truly automate the creation of the PowerPoint deck or Word doc, we can embed the code in an app that runs on our computer or in the cloud. That will be the subject of a later post.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Python Tools</category>
  <guid>https://finance-with-ai.org/posts/05-building/</guid>
  <pubDate>Wed, 07 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/05-building/building.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Prompt Engineering (or Not)</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/06-prompts/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/06-prompts/prompts.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>I use <a href="https://mentimeter.com/">Menti</a> surveys periodically to ask students what they would like to learn more about, and how to write effective prompts frequently shows up. In the first bit of time after ChatGPT 3.5 was introduced, there was a lot of chatter online about prompt engineering. This seems to have died down somewhat, and for good reason. The models are so good now that they don’t generally require any special prompting. In particular, you do not need to tell Julius “you are an expert coder …” If any role-setting is even needed now, which is doubtful, I think it must be supplied in the context provided by Julius to the LLMs.</p>
<p>I take advice on this topic from <a href="https://mgmt.wharton.upenn.edu/profile/emollick/">Ethan Mollick</a>, a Wharton management professor who studies these things and whose blog, <a href="https://www.oneusefulthing.org/">One Useful Thing</a>, you should certainly follow, if you do not already. I direct students to one of Mollick’s posts in particular, which discusses <a href="https://www.oneusefulthing.org/p/getting-started-with-ai-good-enough">good enough prompting</a>. Mollick suggests that instead of worrying about how to write prompts, people should treat an LLM as an “infinitely patient coworker.” I find that I naturally come back to this several times in my course, reminding students “Remember what Ethan Mollick said: treat AI as an infinitely patient coworker.” Actually, I modify the quote from “coworker” to “colleague.” The term “coworker” suggests a peer to me, but AI can serve equally well as a senior colleague who mentors, or a junior colleague who assists, or a peer who collaborates. And, it can move seamlessly from one to the other.</p>
<p>A question students ask is whether they should give specific instructions in a chat, or just a brief statement of what they want and then see what they get. Here, I say “think of AI as an ininitely patient assistant.” How detailed should the instructions be that you give an assistant? You can be very detailed, but that is a waste of time if the assistant is competent to do the task alone. On the other hand, if you are not detailed, you may find the assistant does something different from what you want, and you have to send him/her/it back to do it again. This process could go on for quite awhile and end up being a waste of time. How to know which path to follow? You need to know your assistant. So, I encourage students to experiment to learn the AI’s capabilities. Some tasks will have appeared frequently in its training data, and it will need very little instruction. It may be less familiar with others and need more. Here, I stress the “infinitely patient” part. You can experiment all you want.</p>
<p>If you find yourself on an iterative path of correcting errors, it can often be useful to just start a new chat and this time give detailed instructions. The frustrating part about correcting errors is that the LLM will regenerate code each time and sometimes, when it tries to fix one error, it introduces new errors (I mean doing something other than what you want, not syntax errors that it will fix on its own) in code that worked fine before. If this begins to happen, it is probably time for a fresh start.</p>
<p>What about tasks that involve multiple steps? Should you ask for everything you want in a single prompt or just ask for one step at a time? Again, I ask students to experiment. What they consistently report back to me is that it is better to just ask for one step at a time. However, one thing to keep in mind is that an LLM can be somewhat forgetful. Even though the context windows are large enough today that an LLM will be able to re-read your entire chat each time you prompt it, it cannot be equally attentive to everything in the chat. So, it can be helpful to prompt it in later steps to “use this that you got before and that that you got before and …” instead of relying on it knowing what it should use from previous steps. In order to ensure that the LLM correctly recovers what it created in previous steps, I find it very helpful to structure each step as: “create a python function that … and save it as a .py file”” Then in subsequent steps, I can say “read the .py file and use the python function to …” Then, each successive step can be taken without prior code being rewritten.</p>
<p>What do you think? What works for you? Let us know in the comments below.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>AI Overview</category>
  <guid>https://finance-with-ai.org/posts/06-prompts/</guid>
  <pubDate>Wed, 07 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/06-prompts/prompts.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>CAPM</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/04-capm/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/04-capm/capm.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>Calculating betas is an easy exercise to do with Julius. We can also estimate the market risk premium, and we can get the risk-free rate from FRED, so we can estimate the cost of equity capital according to the CAPM. This exercise provides the opportunity to explore <a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">Ken French’s data library</a> while getting market excess returns and risk-free rates.</p>
<p>To estimate betas, we need stock excess returns and market excess returns. I follow the usual academic convention of monthly returns over a 5-year period. To get monthly stock returns we can use yfinance (see <a href="https://finance-with-ai.org/posts/02-online-data/">here</a>). To get adjusted closing prices at a monthly frequency, simply ask Julius for them (the LLM will either use period=“1mo” in yf.download or it will use the pandas resample method to downsample daily prices to monthly prices). Ask for a bit more than five years, because we may lose some months when merging with the market data. Then compute returns as percent changes.</p>
<p>To get market excess returns and the risk-free rate, we can use French’s data library. It’s interesting to start by asking Julius to list the datasets available in French’s data library. Then ask Julius to get the monthly three factors using pandas-datareader starting in 1926 and to compute the mean of Mkt-RF for the market risk premium estimate. You’ll want to annualize the market risk premium estimate (or you could just ask for the annual factors and the mean of annual Mkt-RF). If you don’t explicitly ask for pandas-datareader to be used, the LLM may write code to directly read the csv files on French’s website into pandas dataframes, which doesn’t work well, because each file contains text and contains multiple tables (monthly, annual, etc.). It will recover from that error, but it saves time to ask for pandas-datareader at the outset.</p>
<p>To estimate betas, we want to first do an inner merge of the Fama-French data with the stock return data. There are two issues. First, the stock return data will be in decimals and the Fama-French data is in percents. The LLM will probably notice that, but it is good to explicitly ask to convert the stock returns to percents or the Fama-French data to decimals (your choice). The second issue is that the dates will be in different formats. Pandas-datareader will return the Fama-French dates in what is called the pandas period format, whereas the stock return format will be in the pandas timestamp format. Julius will figure this out also, but it may speed up the merge to warn it that the date formats will need to be reconciled. Once the data is merged, keep the last 60 months for which there are no missing data, calculate excess stock returns by subtracting RF (which is in the Fama-French three factor dataset), and then ask Julius to run the regression.</p>
<p>Once the beta is estimated, the final step is to get the current risk-free rate. I ask Julius to get the latest value of the three-month T-bill yield from FRED, but it can get different rates if you prefer something else. At this point, you can just ask Julius to compute the cost of equity. The LLMs know the CAPM formula.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Finance</category>
  <guid>https://finance-with-ai.org/posts/04-capm/</guid>
  <pubDate>Tue, 06 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/04-capm/capm.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Online Data</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/02-online-data/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/02-online-data/online.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>We can upload files to Julius as with other chatbots. We can then chat about the data with the benefit of python. In fact, Julius.ai started life as the “Chat with Your Data” plug-in for ChatGPT. However, Julius can also grab online data. Computing stock returns from <a href="https://finance.yahoo.com/">Yahoo Finance</a> data is a good place to start. The yfinance library is the best python library for accessing Yahoo Finance. The data begins in 1970. To get the longest possible history for a ticker, we can ask Julius to get data starting in 1970. We can specify other dates, and we can also specify the frequency of the data - daily, weekly, monthly, quarterly, annual.</p>
<p>Yahoo Finance computes dividend and split adjusted closing prices. We can compute total close-to-close returns, including dividend returns, as percent changes of the adjusted closing prices.<sup>1</sup> The yfinance library recently changed to returning the adjusted prices by default rather than returning standard (split-adjusted) prices. The confusing part is that it now calls the adjusted prices returned by default “Close” rather than the former “Adj Close.” I recommend prompting the LLM to use the latest version of yfinance and explicitly prompting the LLM to get the “Close” instead of “Adj Close.”</p>
<p>A more complex but also more transparent solution to the Close/Adj Close confusion is to prompt the LLM to use the yfinance download function with auto_adjust set to False (this was the old behavior) and to get both the “Close” and “Adj Close.” Percent changes in “Adj Close” are what we want for returns. To show students the difference between the two, we can ask for percent changes in both and then filter to dates where the percent changes differ by more than 0.00001 or so. Those dates will be the ex-dividend days. The difference between the two percent changes on those days is the quarterly dividend yield.</p>
<p>An additional wrinkle with yfinance is that older versions have recently been return “rate limit” errors. Ask Julius to upgrade yfinance if you encounter that.</p>
<p><a href="https://fred.stlouisfed.org/">FRED</a> (Federal Reserve Economic Data) is a standard source for macroeconomic data, including GDP, exchange rates, Treasury and corporate bond yields, crude oil prices, etc. The pandas-datareader library is the best python library for accessing FRED. We can go to the FRED website and find the data we want, but Julius is quicker. For example, “get the history of 10-year Treasury yields from FRED using pandas-datareader at a daily frequency and plot them.” In subsequent posts, we’ll explore other online data, including Ken French’s data library and the SEC EDGAR site.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>There is a slight caveat that the percent change of the adjusted closing price on an ex-dividend day takes the dividend out of the denominator of the price ratio rather than adding it to the numerator, but, given typical quarterly dividend yields, this has a negligible effect. Percent changes of adjusted closing prices on all days other than ex-dividend days equal percent changes in split-adjusted closing prices.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Finance</category>
  <category>Python Tools</category>
  <guid>https://finance-with-ai.org/posts/02-online-data/</guid>
  <pubDate>Mon, 05 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/02-online-data/online.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Data Visualization</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/03-visualize/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/03-visualize/visualize2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>Python has very versatile plotting libraries. The primary libraries are matplotlib and seaborn, but there are others - for example, plotly and other libraries create interactive html plots. All of the standard plot types are available. For ideas, see <a href="https://matplotlib.org/stable/gallery/">here</a> for matplotlib examples and <a href="https://seaborn.pydata.org/examples/index.html">here</a> for seaborn. We can ask Julius to adjust the figure size, font sizes, tick locations, tick labels, axis labels, title, legend positioning, and more. Figures can be saved and downloaded as jpegs, pngs, pdfs, or other types. Different themes can also be applied – gridded or not gridded, light or dark background, legend or no legend, etc. We can put multiple plots in the same figure, and they can share a legend if it is appropriate. We can add annotations within plots. I recommend encouraging students to ask Julius what is possible.</p>
<p>Three particular seaborn features are worth mentioning. The regplot function creates scatter plots with regression lines. The default is to include a confidence interval around the line, but we can ask for it to be removed. The “hue” argument in seaborn provides a good means of plotting three-dimensional data. In addition to the x and y dimensions, a third dimension is represented by color. This works for scatter plots, bar plots, box plots, density plots, and other types. We can include separate regression lines for different colors in a scatter plot. We can also use the type of marker as a third dimension instead of color, or we can use color together with marker type to show four dimensions, though that becomes hard to interpret. I recommend indicating a fourth dimension by including multiple subplots in the same figure. The third feature that should be shown to students is the pairplot function. It creates a matrix of scatter plots (with density plots or histograms on the diagonal), so the correlations among multiple variables can be seen simultaneously.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>Python Tools</category>
  <guid>https://finance-with-ai.org/posts/03-visualize/</guid>
  <pubDate>Mon, 05 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/03-visualize/visualize2.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Julius and the Democratization of Coding</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/01-julius/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/01-julius/julius.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:30.0%"></p>
</figure>
</div>
<p>The world is aware that generative AI has made coders more efficient, but I don’t know if there is as much recognition of the more important fact that gen AI has made coding accessible to non-coders. I expect this to change rapidly by word of mouth: Once exposed to the wonder of coding with gen AI, one cannot help but want to share the word. We can accelerate that change for our students.</p>
<p>There are many IDEs (integrated development environements) that incorporate AI assistance, among which <a href="https://www.cursor.com/en">Cursor</a> may be the most popular at the moment. Those tools are fantastic, but the variety of options makes them intimidating to non-coders. The leading chatbots also have “code interpreters” that execute generated code to respond to prompts. But, as of this writing, those interpreters are closed systems. They provide a fixed menu of libraries and do not allow the user to install more. <a href="https://julius.ai">Julius.ai</a> bridges the gap. It is a full-fledged coding environment, allowing the user to install any library he or she wishes. At the same time, it has the ease of use of a chatbot (and get the 50% academic discount by emailing team@julius.ai from your university email).</p>
<p>The Julius website states that it provides an “intuitive way to analyze and visualize data without having to code, making statistical analysis accessible to everyone.” Democratizing coding is the goal of the Julius developers. However, the focus on statistical analysis understates what Julius has to offer. You can choose to work in either python or R. If you choose python, which I recommend, then you can do anything with Julius that python can do, and python can do pretty much everything. We’ll explore lots of applications in subsequent posts. I’ll refer to Julius throughout my posts, because I don’t think there is anything superior available now and because it is what I use in my course, but the things we discuss will frequently apply to other AI + python setups as well.</p>
<p>Julius is a wrapper around large language models (LLMs), including the latest models from OpenAI and Anthropic as of this writing. Julius sends the user’s prompts to the user’s selected LLM (the general consensus in the blogosphere, and my own impression, is that the Anthropic models Claude 3.5 and Claude 3.7 are the best coders available at this time) with additional context created by the Julius developers. If the LLM generates code, then Julius’s servers execute it. The user can see the code as it is written and see what the code creates. The chat is very informative, telling the user what the plan is before the code is generated and then interpreting and explaining the results afterwards. A benefit of this process is that students learn something about coding in a relatively painless way.</p>
<p>A valid concern about gen AI coding for non-coders is that an LLM may make a mistake that the user cannot detect. When OpenAI released GPT 3.5 in 2022, it frequently hallucinated. It is natural to worry about hallucinations in AI-generated code. One saving grace is that the models have improved tremendously since 2022, and hallucinations are much less common. An equally important consideration is the nature of coding. Hallucinations about facts in coding would be hallucinations about syntax, and incorrect syntax won’t run. Syntax errors certainly happen, but Julius sends the error messages back to the LLM in an iterative manner until, almost always, the syntax is corrected and the code runs. The type of error that usually happens with gen AI coding for non-coders results from the LLM not fully understanding what the user wants. To guard against this, it is important to engage in a conversation with the LLM about what you want, what it understands regarding what you want, what it plans to do, and what it did. Finally, we should try to check code generated by an LLM by testing it on small examples.</p>
<p>It is obviously easier to ensure that the LLM did what you want if you can read python code. So, how much python to teach students? Luckily, python is pretty easy to read if you understand the basic structure. I take some time in early sessions of my course to point out: “this is an object, a method of the object is being applied here, this is a function, this is a list …” I also recorded some introductory videos, which are linked in the “Course Materials” (though I doubt they were watched). As I said, a valuable side effect of the course is that students learn something about python, which they feel they need to do, but which they don’t really have the time to do if they had to learn it in a pre-AI mode.</p>
<p>There are products that compete with Julius in one way or another that are certainly worth showing to students, and new products are appearing at a rapid pace. Plus, the leading LLM providers are expanding their services. An example of a competing product is <a href="https://vizly.fyi/">Vizly</a>. It has the same data analysis/visualization focus as Julius. The developers were previously at Plotly, and the default plotting library is plotly, which creates very nice interactive HTML plots (you can also use plotly with Julius). Vizly is worth exploring, but I don’t have a lot of experience with it. Casting a wider net, students should be introduced to <a href="https://colab.research.google.com/">Google Colab</a>. It is not a chatbot, but it is a free JupyterLab environment with free AI assistance provided by the latest Google model (Gemini 2.5 as of this writing). You start by opening a new notebook or exploring the provided Introduction to Colab notebook. I recommend starting a notebook by asking the AI to mount your Google Drive. Then you can read and write files from your Google Drive (ask the AI to do that also). You can also save your Jupyter notebook there. Casting the net even wider, I highly recommend <a href="https://replit.com/~">Replit</a>. It creates very professional web apps, writing the HTML and CSS to create the user interface along with (usually) python to do the actual work. It also provides a hosting service, so you can deploy your app online with just a few clicks. We’ll explore creating apps with Julius in subsequent posts using the python streamlit and gradio libraries.</p>
<p>There are many more AI + coding tools out there. Please share your favorites, and share your experiences in teaching finance with AI, in the comments below.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <category>AI Overview</category>
  <guid>https://finance-with-ai.org/posts/01-julius/</guid>
  <pubDate>Sun, 04 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/01-julius/julius.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Teaching Finance with AI</title>
  <dc:creator>Kerry Back</dc:creator>
  <link>https://finance-with-ai.org/posts/00-welcome/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://finance-with-ai.org/posts/00-welcome/logo.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>The purpose of this blog and the site <a href="https://finance-with-ai.org">finance-with-ai.org</a> is to communicate things I’ve learned about teaching MBA students at Rice University how to do financial analyses using “AI + coding” and more broadly how generative AI can and is being used in the finance industry. I will post short notes on what I’ve learned about teaching this topic and on related things I find interesting. The blog is intended to be a resource for finance instructors at the undergraduate, MBA, and MSF levels.</p>
<p>The current effectiveness of AI + coding varies somewhat between corporate finance and investments applications. Here, I lump fundamental security analysis with corporate finance. There are many topics in the investments area for which spreadsheets were never well equipped and for which spreadsheets are seldom used in practice. Previously, it was difficult to teach those topics by example, but now students can prompt an LLM to generate code for them.</p>
<p>Even in capital budgeting, financial statement analysis, and pro forma financial valuation, AI is already very valuable. It is not yet ready to replace spreadsheets, but it can be a useful complement to spreadsheets. AI can be used as a collaborator – “tell me how you would do this” or “you do it your way, and I’ll do it my way, and then we can compare answers.” As the models improve, I expect the world to shift more and more to AI in lieu of spreadsheets even for corporate finance applications. Of course, Hewlett-Packard is still making the 12C financial calculator, and Microsoft will undoubtedly sell Excel for many years to come, but I think AI + coding will eventually dominate. To prepare our students for that world, we should start teaching them now about what is likely to lie ahead.</p>
<p>In the Rice MBA program, a full semester core class in the fall of the first year is followed by two half-semester electives in the spring: a spreadsheet-based course in applied finance and then my course in AI-assisted finance. We cover some of the same topics in all three courses: capital budgeting, mean-variance efficiency, the CAPM, … This is a good arrangement. Students’ understanding of the topics is reinforced and deepened throughout the sequence. Each course also introduces new topics, expanding the frontier of students’ knowledge. I mention this here mainly to provide context. I view the role of my course as four-fold: to show students how to use the new tool of AI + coding, to show students something about how AI is implemented and used in the finance industry, to deepen students’ understanding of core finance topics, and to introduce students to some important finance topics they may have not yet encountered (without stepping too much on the toes of second-year instructors!). I hope that my recounting of my attempts to accomplish this may be of some help to others.</p>
<p>What do you think? Please share your thoughts in the comments below.</p>
<hr>
<p><em>Also on substack at <a href="https://kerryback.substack.com">kerryback.substack.com</a></em></p>



 ]]></description>
  <guid>https://finance-with-ai.org/posts/00-welcome/</guid>
  <pubDate>Sat, 03 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://finance-with-ai.org/posts/00-welcome/logo.png" medium="image" type="image/png" height="102" width="144"/>
</item>
</channel>
</rss>
